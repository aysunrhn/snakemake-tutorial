{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to define a good wine?\n",
    "\n",
    "Our next example will be on wine. We'll be using the [Wine Quality dataset](https://archive.ics.uci.edu/dataset/186/wine+quality) from UC Irvine Machine Learning Repository[<sup>1</sup>](#fn1). It consists of 4898 samples and 11 features, it's an example dataset that can be used for both regression and classification. You can find the dataset in my GitHub repository as well. We'll use it to figure out what aspects of wine make it \"good\", and explore some features of Snakemake, such as\n",
    "\n",
    "- **checkpoints**: to handle dynamically generated files\n",
    "- **wildcards**: to handle multiple types of regression models\n",
    "\n",
    "These will help make our workflow more robust and flexible at the same time. Our workflow consists of 5 steps:\n",
    "1. Preprocess: to clean, scale and split the dataset into train and test sets\n",
    "2. Dynamic model selection: to dynamically determine which model to train based on the dataset size\n",
    "3. Train: to train regression model(s) (e.g. Linear Regression, Ridge and Lasso, in this example)\n",
    "4. Evaluate: to evaluate the model performance using mean squared error (MSE)\n",
    "5. Visualize: to generate plots comparing model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checkpoints\n",
    "- Checkpoints allow Snakemake to dynamically determine inputs for a rule based on outputs generated during runtime. This is useful when the exact inputs for downstream rules are unknown until an upstream rule has executed. In our example, we'll use checkpoints to dynamically select which regression models to train based on the characteristics of the preprocessed training dataset. For example, we'll select `Ridge` and `Lasso` as the models to train if our dataset has more than 1000 training samples. If it's less than that we'll go with `LinearRegression`\n",
    "- The checkpoint writes the selected models to a file (`output/selected_models.txt` in this case) which is then used as input for the `train` rule.\n",
    "- The `scripts/select_models.py` looks like this:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load preprocessed training data\n",
    "    X_train = pd.read_csv(snakemake.input[0])\n",
    "\n",
    "    # Dynamically decide which models to train\n",
    "    selected_models = []\n",
    "    if X_train.shape[0] > 1000:  # Example condition: large dataset\n",
    "        selected_models.extend([\"Ridge\", \"Lasso\"])\n",
    "    else:  # Small dataset\n",
    "        selected_models.append(\"LinearRegression\")\n",
    "\n",
    "    # Save selected models to file\n",
    "    with open(snakemake.output[0], \"w\") as f:\n",
    "        for model in selected_models:\n",
    "            f.write(model + \"\\n\")\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wildcards\n",
    "\n",
    "- In the `train` rule, we use wildcards to dynamically read the list of models from the checkpoints output (`output/selected_models.txt`) and expand `{model}` wildcard accordingly. This can be done using a `lambda` function in the `Snakefile`. \n",
    "    ```python\n",
    "    rule train:\n",
    "        input:\n",
    "            X_train=\"output/X_train.csv\",\n",
    "            y_train=\"output/y_train.csv\"\n",
    "        output:\n",
    "            \"output/models/{model}.csv\"\n",
    "        params:\n",
    "            model_list=lambda wildcards, input: open(\"output/selected_models.txt\").read().strip().split()\n",
    "        script:\n",
    "            \"scripts/train.py\"\n",
    "    ```\n",
    "\n",
    "- Our script, `scripts/train.py` takes the wildcard as input as follows:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "    import os\n",
    "\n",
    "    # Load preprocessed data\n",
    "    X_train = pd.read_csv(snakemake.input[0])\n",
    "    y_train = pd.read_csv(snakemake.input[1]).values.ravel()\n",
    "\n",
    "    # Determine model type from wildcard\n",
    "    model_type = snakemake.wildcards.model\n",
    "\n",
    "    if model_type == \"LinearRegression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_type == \"Ridge\":\n",
    "        model = Ridge(alpha=1.0)\n",
    "    elif model_type == \"Lasso\":\n",
    "        model = Lasso(alpha=0.1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model coefficients\n",
    "    coefficients = pd.DataFrame(model.coef_, columns=[\"Coefficient\"])\n",
    "    coefficients.to_csv(snakemake.output[0], index=False)\n",
    "    ```\n",
    "\n",
    "- To avoid redundancy in the `evaluate` rule, we can use **dynamic wildcards**. Since we already defined the regression models available for the `train` rule, we don't need to redefine it. By using dynamic wildcards, our `evaluate` rule can automatically adapt.\n",
    "    ```python\n",
    "    rule evaluate:\n",
    "        input:\n",
    "            models=expand(\"output/models/{{model}}.csv\", model=lambda wildcards: open(\"output/selected_models.txt\").read().strip().split()),\n",
    "            X_test=\"output/X_test.csv\",\n",
    "            y_test=\"output/y_test.csv\"\n",
    "        output:\n",
    "            \"output/model_results.csv\"\n",
    "        script:\n",
    "            \"scripts/evaluate.py\"\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our workflow to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /usr/bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob stats:\n",
      "job          count\n",
      "---------  -------\n",
      "all              1\n",
      "evaluate         1\n",
      "visualize        1\n",
      "total            3\n",
      "\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Thu Jan  9 15:08:48 2025]\u001b[0m\n",
      "\u001b[32mrule evaluate:\n",
      "    input: output/models/Ridge.csv, output/models/Lasso.csv, output/X_test.csv, output/y_test.csv\n",
      "    output: output/model_results.csv\n",
      "    jobid: 2\n",
      "    reason: Missing output files: output/model_results.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aurhan/Work/Snakemake tutorial/snakemake-tutorial/wine-tutorial/.snakemake/scripts/tmpf22tqi7t.evaluate.py\", line 23, in <module>\n",
      "    y_pred = X_test @ coef  # Perform the dot product between X_test and coefficients\n",
      "  File \"/home/aurhan/miniconda3/envs/snakemake-tutorial/lib/python3.9/site-packages/pandas/core/frame.py\", line 1787, in __matmul__\n",
      "    return self.dot(other)\n",
      "  File \"/home/aurhan/miniconda3/envs/snakemake-tutorial/lib/python3.9/site-packages/pandas/core/frame.py\", line 1748, in dot\n",
      "    raise ValueError(\n",
      "ValueError: Dot product shape mismatch, (11, 1) vs (11,)\n",
      "\u001b[32m[Thu Jan  9 15:08:50 2025]\u001b[0m\n",
      "\u001b[31mError in rule evaluate:\n",
      "    jobid: 2\n",
      "    input: output/models/Ridge.csv, output/models/Lasso.csv, output/X_test.csv, output/y_test.csv\n",
      "    output: output/model_results.csv\n",
      "\u001b[0m\n",
      "\u001b[31mRuleException:\n",
      "CalledProcessError in file /home/aurhan/Work/Snakemake tutorial/snakemake-tutorial/wine-tutorial/Snakefile, line 48:\n",
      "Command 'set -euo pipefail;  /home/aurhan/miniconda3/envs/snakemake-tutorial/bin/python3.9 '/home/aurhan/Work/Snakemake tutorial/snakemake-tutorial/wine-tutorial/.snakemake/scripts/tmpf22tqi7t.evaluate.py'' returned non-zero exit status 1.\n",
      "  File \"/home/aurhan/Work/Snakemake tutorial/snakemake-tutorial/wine-tutorial/Snakefile\", line 48, in __rule_evaluate\n",
      "  File \"/home/aurhan/miniconda3/envs/snakemake-tutorial/lib/python3.9/concurrent/futures/thread.py\", line 58, in run\u001b[0m\n",
      "\u001b[33mShutting down, this might take some time.\u001b[0m\n",
      "\u001b[31mExiting because a job execution failed. Look above for error message\u001b[0m\n",
      "\u001b[33mComplete log: .snakemake/log/2025-01-09T150848.226976.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "<span id=\"fn1\">1. </span> Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. 2009. Wine Quality [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56S3T."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snakemake-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
