{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to define a good wine?\n",
    "\n",
    "Our next example will be on wine. We'll be using the [Wine Quality dataset](https://archive.ics.uci.edu/dataset/186/wine+quality) from UC Irvine Machine Learning Repository[<sup>1</sup>](#fn1). It consists of 4898 samples and 11 features, it's an example dataset that can be used for both regression and classification. You can find the dataset in my GitHub repository as well. We'll use it to figure out what aspects of wine make it \"good\", and explore some features of Snakemake, such as\n",
    "\n",
    "- **checkpoints**: to handle dynamically generated files\n",
    "- **wildcards**: to handle multiple types of regression models\n",
    "\n",
    "These will help make our workflow more robust and flexible at the same time. Our workflow consists of 5 steps:\n",
    "1. Preprocess: to clean, scale and split the dataset into train and test sets\n",
    "2. Dynamic model selection: to dynamically determine which model to train based on the dataset size\n",
    "3. Train: to train regression model(s) (e.g. Linear Regression, Ridge and Lasso, in this example)\n",
    "4. Evaluate: to evaluate the model performance using mean squared error (MSE)\n",
    "5. Visualize: to generate plots comparing model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checkpoints\n",
    "- Checkpoints allow Snakemake to dynamically determine inputs for a rule based on outputs generated during runtime. This is useful when the exact inputs for downstream rules are unknown until an upstream rule has executed. In our example, we'll use checkpoints to dynamically select which regression models to train based on the characteristics of the preprocessed training dataset. For example, we'll select `Ridge` and `Lasso` as the models to train if our dataset has more than 1000 training samples. If it's less than that we'll go with `LinearRegression`\n",
    "- The checkpoint writes the selected models to a file (`output/selected_models.txt` in this case) which is then used as input for the `evaluate` rule directly.\n",
    "- The `scripts/select_models.py` looks like this:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load preprocessed training data\n",
    "    X_train = pd.read_csv(snakemake.input[0])\n",
    "\n",
    "    # Dynamically decide which models to train\n",
    "    selected_models = []\n",
    "    if X_train.shape[0] > 1000:  # Example condition: large dataset\n",
    "        selected_models.extend([\"Ridge\", \"Lasso\"])\n",
    "    else:  # Small dataset\n",
    "        selected_models.append(\"LinearRegression\")\n",
    "\n",
    "    # Save selected models to file\n",
    "    with open(snakemake.output[0], \"w\") as f:\n",
    "        for model in selected_models:\n",
    "            f.write(model + \"\\n\")\n",
    "    ```\n",
    "\n",
    "- And the corresponding checkpoint, `select_models` in our Snakefile is:\n",
    "    ```python\n",
    "    checkpoint select_models:\n",
    "        input:\n",
    "            \"output/X_train.csv\"\n",
    "        output:\n",
    "            \"output/selected_models.txt\"\n",
    "        script:\n",
    "            \"scripts/select_models.py\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wildcards\n",
    "\n",
    "- In the `train` rule, we use the `{model}` wildcard to determine which models to train and save the model coefficients. The wildcard is indirectly set by the `evaluate` rule. To explain this better, we need to look at the `evaluate` rule first. Below is what our `train` rule looks like.\n",
    "    ```python\n",
    "    rule evaluate:\n",
    "        input:\n",
    "            models=lambda wildcards: expand(\n",
    "                \"output/models/{model}.csv\",\n",
    "                model=open(checkpoints.select_models.get().output[0]).read().strip().split()\n",
    "            ),\n",
    "            X_test=\"output/X_test.csv\",\n",
    "            y_test=\"output/y_test.csv\"\n",
    "        output:\n",
    "            \"output/model_results.csv\"\n",
    "        script:\n",
    "            \"scripts/evaluate.py\"\n",
    "    ```\n",
    "\n",
    "- The `scripts/evaluate.py` script takes 3 inputs, first one being the list of models written in the `select_models` checkpoint output. We can retrieve this output with the `get()` function, read its content and store the list of model types in the `{model}` wildcard. We use this wildcard to feed the corresponding model coefficients file path `output/models/{model}.csv`\n",
    "- To successfully run the `evaluate` rule, Snakemake needs the 3 input files: path to the model coefficients file, test features and test labels. While the test features and labels are produced as output by the `preprocess` rule, we need to run the `train` rule to obtain the model coefficients based on the output file name pattern we defined in the `train` rule.\n",
    "- When building the DAG of our workflow, Snakemake places the `train` rule before the `evaluate` rule. That's why if we try to run the `train` rule directly, it will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[31mWorkflowError:\n",
      "Target rules may not contain wildcards. Please specify concrete files or a rule without wildcards at the command line, or have a rule without wildcards at the very top of your workflow (e.g. the typical \"rule all\" which just collects all results you want to generate in the end).\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --cores 1 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We cannot place wildcards in the ultimate target rule, because Snakemake cannot figure out what files to produce. Instead, we can either:\n",
    "1. Write an `all` rule in our `Snakefile` which defines the target the output, Snakemake recognizes the `all` rule name and runs that rule by default if no other rule name is specified at the CLI.\n",
    "    ```python\n",
    "    rule all:\n",
    "        input:\n",
    "            \"output/visualizations/model_performance.png\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /usr/bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob stats:\n",
      "job              count\n",
      "-------------  -------\n",
      "all                  1\n",
      "evaluate             1\n",
      "preprocess           1\n",
      "select_models        1\n",
      "visualize            1\n",
      "total                5\n",
      "\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:24 2025]\u001b[0m\n",
      "\u001b[32mrule preprocess:\n",
      "    input: data/winequality-red.csv\n",
      "    output: output/X_train.csv, output/X_test.csv, output/y_train.csv, output/y_test.csv\n",
      "    jobid: 4\n",
      "    reason: Missing output files: output/y_test.csv, output/X_train.csv, output/X_test.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:26 2025]\u001b[0m\n",
      "\u001b[32mFinished job 4.\u001b[0m\n",
      "\u001b[32m1 of 5 steps (20%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:26 2025]\u001b[0m\n",
      "\u001b[32mcheckpoint select_models:\n",
      "    input: output/X_train.csv\n",
      "    output: output/selected_models.txt\n",
      "    jobid: 3\n",
      "    reason: Missing output files: output/selected_models.txt; Input files updated by another job: output/X_train.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[33mDAG of jobs will be updated after completion.\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:27 2025]\u001b[0m\n",
      "\u001b[32mFinished job 3.\u001b[0m\n",
      "\u001b[32m2 of 5 steps (40%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:27 2025]\u001b[0m\n",
      "\u001b[32mrule train:\n",
      "    input: output/X_train.csv, output/y_train.csv\n",
      "    output: output/models/Lasso.csv\n",
      "    jobid: 8\n",
      "    reason: Missing output files: output/models/Lasso.csv\n",
      "    wildcards: model=Lasso\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:29 2025]\u001b[0m\n",
      "\u001b[32mFinished job 8.\u001b[0m\n",
      "\u001b[32m3 of 7 steps (43%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:29 2025]\u001b[0m\n",
      "\u001b[32mrule train:\n",
      "    input: output/X_train.csv, output/y_train.csv\n",
      "    output: output/models/Ridge.csv\n",
      "    jobid: 7\n",
      "    reason: Missing output files: output/models/Ridge.csv\n",
      "    wildcards: model=Ridge\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:31 2025]\u001b[0m\n",
      "\u001b[32mFinished job 7.\u001b[0m\n",
      "\u001b[32m4 of 7 steps (57%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:31 2025]\u001b[0m\n",
      "\u001b[32mrule evaluate:\n",
      "    input: output/models/Ridge.csv, output/models/Lasso.csv, output/X_test.csv, output/y_test.csv\n",
      "    output: output/model_results.csv\n",
      "    jobid: 2\n",
      "    reason: Missing output files: output/model_results.csv; Input files updated by another job: output/models/Ridge.csv, output/models/Lasso.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:33 2025]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m5 of 7 steps (71%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:33 2025]\u001b[0m\n",
      "\u001b[32mrule visualize:\n",
      "    input: output/model_results.csv\n",
      "    output: output/visualizations/model_performance.png\n",
      "    jobid: 1\n",
      "    reason: Missing output files: output/visualizations/model_performance.png; Input files updated by another job: output/model_results.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:36 2025]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m6 of 7 steps (86%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:36 2025]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: output/visualizations/model_performance.png\n",
      "    jobid: 0\n",
      "    reason: Input files updated by another job: output/visualizations/model_performance.png\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:36 2025]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m7 of 7 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: .snakemake/log/2025-01-17T123024.024420.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --cores 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Or we can explicitly specify the output we want to produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /usr/bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob stats:\n",
      "job             count\n",
      "------------  -------\n",
      "clean_output        1\n",
      "total               1\n",
      "\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:38 2025]\u001b[0m\n",
      "\u001b[32mrule clean_output:\n",
      "    jobid: 0\n",
      "    reason: Rules with neither input nor output files are always executed.\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:38 2025]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m1 of 1 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: .snakemake/log/2025-01-17T123037.397202.snakemake.log\u001b[0m\n",
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /usr/bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob stats:\n",
      "job              count\n",
      "-------------  -------\n",
      "evaluate             1\n",
      "preprocess           1\n",
      "select_models        1\n",
      "visualize            1\n",
      "total                4\n",
      "\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:40 2025]\u001b[0m\n",
      "\u001b[32mrule preprocess:\n",
      "    input: data/winequality-red.csv\n",
      "    output: output/X_train.csv, output/X_test.csv, output/y_train.csv, output/y_test.csv\n",
      "    jobid: 3\n",
      "    reason: Missing output files: output/X_train.csv, output/X_test.csv, output/y_test.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:42 2025]\u001b[0m\n",
      "\u001b[32mFinished job 3.\u001b[0m\n",
      "\u001b[32m1 of 4 steps (25%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:42 2025]\u001b[0m\n",
      "\u001b[32mcheckpoint select_models:\n",
      "    input: output/X_train.csv\n",
      "    output: output/selected_models.txt\n",
      "    jobid: 2\n",
      "    reason: Missing output files: output/selected_models.txt; Input files updated by another job: output/X_train.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[33mDAG of jobs will be updated after completion.\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:44 2025]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m2 of 4 steps (50%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:44 2025]\u001b[0m\n",
      "\u001b[32mrule train:\n",
      "    input: output/X_train.csv, output/y_train.csv\n",
      "    output: output/models/Lasso.csv\n",
      "    jobid: 7\n",
      "    reason: Missing output files: output/models/Lasso.csv\n",
      "    wildcards: model=Lasso\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:46 2025]\u001b[0m\n",
      "\u001b[32mFinished job 7.\u001b[0m\n",
      "\u001b[32m3 of 6 steps (50%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:46 2025]\u001b[0m\n",
      "\u001b[32mrule train:\n",
      "    input: output/X_train.csv, output/y_train.csv\n",
      "    output: output/models/Ridge.csv\n",
      "    jobid: 6\n",
      "    reason: Missing output files: output/models/Ridge.csv\n",
      "    wildcards: model=Ridge\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:49 2025]\u001b[0m\n",
      "\u001b[32mFinished job 6.\u001b[0m\n",
      "\u001b[32m4 of 6 steps (67%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:49 2025]\u001b[0m\n",
      "\u001b[32mrule evaluate:\n",
      "    input: output/models/Ridge.csv, output/models/Lasso.csv, output/X_test.csv, output/y_test.csv\n",
      "    output: output/model_results.csv\n",
      "    jobid: 1\n",
      "    reason: Missing output files: output/model_results.csv; Input files updated by another job: output/models/Lasso.csv, output/models/Ridge.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:51 2025]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m5 of 6 steps (83%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:51 2025]\u001b[0m\n",
      "\u001b[32mrule visualize:\n",
      "    input: output/model_results.csv\n",
      "    output: output/visualizations/model_performance.png\n",
      "    jobid: 0\n",
      "    reason: Missing output files: output/visualizations/model_performance.png; Input files updated by another job: output/model_results.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 17 12:30:53 2025]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m6 of 6 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: .snakemake/log/2025-01-17T123039.468093.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --cores 1 clean_output\n",
    "!snakemake --cores 1 \"output/visualizations/model_performance.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Another option is to run the downstream rules `evaluate` or `visualize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's end this tutorial with a DAG of our workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --rulegraph --cores 1 | dot -Tsvg > rulegraph.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](rulegraph.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "<span id=\"fn1\">1. </span> Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. 2009. Wine Quality [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56S3T."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snakemake-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
