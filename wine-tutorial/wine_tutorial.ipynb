{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to define a good wine?\n",
    "\n",
    "Our next example will be on wine. We'll be using the [Wine Quality dataset](https://archive.ics.uci.edu/dataset/186/wine+quality) from UC Irvine Machine Learning Repository[<sup>1</sup>](#fn1). It consists of 4898 samples and 11 features, it's an example dataset that can be used for both regression and classification. You can find the dataset in my GitHub repository as well. We'll use it to figure out what aspects of wine make it \"good\", and explore some features of Snakemake, such as\n",
    "\n",
    "- **checkpoints**: to handle dynamically generated files\n",
    "- **wildcards**: to handle multiple types of regression models\n",
    "\n",
    "These will help make our workflow more robust and flexible at the same time. Our workflow consists of 5 steps:\n",
    "1. Preprocess: to clean, scale and split the dataset into train and test sets\n",
    "2. Dynamic model selection: to dynamically determine which model to train based on the dataset size\n",
    "3. Train: to train regression model(s) (e.g. Linear Regression, Ridge and Lasso, in this example)\n",
    "4. Evaluate: to evaluate the model performance using mean squared error (MSE)\n",
    "5. Visualize: to generate plots comparing model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Checkpoints\n",
    "- Checkpoints allow Snakemake to dynamically determine inputs for a rule based on outputs generated during runtime. This is useful when the exact inputs for downstream rules are unknown until an upstream rule has executed. In our example, we'll use checkpoints to dynamically select which regression models to train based on the characteristics of the preprocessed training dataset. For example, we'll select `Ridge` and `Lasso` as the models to train if our dataset has more than 1000 training samples. If it's less than that we'll go with `LinearRegression`\n",
    "- The checkpoint writes the selected models to a file (`output/selected_models.txt` in this case) which is then used as input for the `train` rule.\n",
    "- The `scripts/select_models.py` looks like this:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load preprocessed training data\n",
    "    X_train = pd.read_csv(snakemake.input[0])\n",
    "\n",
    "    # Dynamically decide which models to train\n",
    "    selected_models = []\n",
    "    if X_train.shape[0] > 1000:  # Example condition: large dataset\n",
    "        selected_models.extend([\"Ridge\", \"Lasso\"])\n",
    "    else:  # Small dataset\n",
    "        selected_models.append(\"LinearRegression\")\n",
    "\n",
    "    # Save selected models to file\n",
    "    with open(snakemake.output[0], \"w\") as f:\n",
    "        for model in selected_models:\n",
    "            f.write(model + \"\\n\")\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wildcards\n",
    "\n",
    "- In the `train` rule, we use wildcards to dynamically read the list of models from the checkpoints output (`output/selected_models.txt`) and expand `{model}` wildcard accordingly. This can be done using a `lambda` function in the `Snakefile`. \n",
    "    ```python\n",
    "    rule train:\n",
    "        input:\n",
    "            X_train=\"output/X_train.csv\",\n",
    "            y_train=\"output/y_train.csv\"\n",
    "        output:\n",
    "            \"output/models/{model}.csv\"\n",
    "        params:\n",
    "            model_list=lambda wildcards, input: open(\"output/selected_models.txt\").read().strip().split()\n",
    "        script:\n",
    "            \"scripts/train.py\"\n",
    "    ```\n",
    "\n",
    "- Our script, `scripts/train.py` takes the wildcard as input as follows:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "    import os\n",
    "\n",
    "    # Load preprocessed data\n",
    "    X_train = pd.read_csv(snakemake.input[0])\n",
    "    y_train = pd.read_csv(snakemake.input[1]).values.ravel()\n",
    "\n",
    "    # Determine model type from wildcard\n",
    "    model_type = snakemake.wildcards.model\n",
    "\n",
    "    if model_type == \"LinearRegression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_type == \"Ridge\":\n",
    "        model = Ridge(alpha=1.0)\n",
    "    elif model_type == \"Lasso\":\n",
    "        model = Lasso(alpha=0.1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model coefficients\n",
    "    coefficients = pd.DataFrame(model.coef_, columns=[\"Coefficient\"])\n",
    "    coefficients.to_csv(snakemake.output[0], index=False)\n",
    "    ```\n",
    "\n",
    "- To avoid redundancy in the `evaluate` rule, we can use **dynamic wildcards**. Since we already defined the regression models available for the `train` rule, we don't need to redefine it. By using dynamic wildcards, our `evaluate` rule can automatically adapt.\n",
    "    ```python\n",
    "    rule evaluate:\n",
    "        input:\n",
    "            models=expand(\"output/models/{{model}}.csv\", model=lambda wildcards: open(\"output/selected_models.txt\").read().strip().split()),\n",
    "            X_test=\"output/X_test.csv\",\n",
    "            y_test=\"output/y_test.csv\"\n",
    "        output:\n",
    "            \"output/model_results.csv\"\n",
    "        script:\n",
    "            \"scripts/evaluate.py\"\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our workflow to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /usr/bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob stats:\n",
      "job          count\n",
      "---------  -------\n",
      "all              1\n",
      "evaluate         1\n",
      "train            2\n",
      "visualize        1\n",
      "total            5\n",
      "\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:16 2025]\u001b[0m\n",
      "\u001b[32mrule train:\n",
      "    input: output/X_train.csv, output/y_train.csv\n",
      "    output: output/models/Lasso.csv\n",
      "    jobid: 7\n",
      "    reason: Code has changed since last execution\n",
      "    wildcards: model=Lasso\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:18 2025]\u001b[0m\n",
      "\u001b[32mFinished job 7.\u001b[0m\n",
      "\u001b[32m1 of 5 steps (20%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:18 2025]\u001b[0m\n",
      "\u001b[32mrule train:\n",
      "    input: output/X_train.csv, output/y_train.csv\n",
      "    output: output/models/Ridge.csv\n",
      "    jobid: 6\n",
      "    reason: Code has changed since last execution\n",
      "    wildcards: model=Ridge\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:20 2025]\u001b[0m\n",
      "\u001b[32mFinished job 6.\u001b[0m\n",
      "\u001b[32m2 of 5 steps (40%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:20 2025]\u001b[0m\n",
      "\u001b[32mrule evaluate:\n",
      "    input: output/models/Ridge.csv, output/models/Lasso.csv, output/X_test.csv, output/y_test.csv\n",
      "    output: output/model_results.csv\n",
      "    jobid: 2\n",
      "    reason: Input files updated by another job: output/models/Ridge.csv, output/models/Lasso.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:22 2025]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m3 of 5 steps (60%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:22 2025]\u001b[0m\n",
      "\u001b[32mrule visualize:\n",
      "    input: output/model_results.csv\n",
      "    output: output/visualizations/model_performance.png\n",
      "    jobid: 1\n",
      "    reason: Input files updated by another job: output/model_results.csv\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:24 2025]\u001b[0m\n",
      "\u001b[32mFinished job 1.\u001b[0m\n",
      "\u001b[32m4 of 5 steps (80%) done\u001b[0m\n",
      "\u001b[33mSelect jobs to execute...\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:24 2025]\u001b[0m\n",
      "\u001b[32mlocalrule all:\n",
      "    input: output/visualizations/model_performance.png\n",
      "    jobid: 0\n",
      "    reason: Input files updated by another job: output/visualizations/model_performance.png\n",
      "    resources: tmpdir=/tmp\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 11:16:24 2025]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m5 of 5 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: .snakemake/log/2025-01-10T111615.917421.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --cores 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!snakemake --rulegraph --cores 1 | dot -Tsvg > rulegraph.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "<span id=\"fn1\">1. </span> Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. 2009. Wine Quality [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56S3T."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snakemake-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
